{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02caa7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\t     logs\t models      requirements.txt\n",
      "experiments  main.ipynb  param2weld  tests\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b55ada",
   "metadata": {},
   "source": [
    "### Tune Hyperparams with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e453c9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed_mean_mae80_ssim20.json  fixed_median_mae80_ssim20.json\n"
     ]
    }
   ],
   "source": [
    "!ls experiments/optuna/configs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b9171ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-03 13:43:15.275021: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-03 13:43:15.278707: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-03 13:43:15.286658: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751542995.299418  179898 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751542995.302897  179898 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751542995.314405  179898 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751542995.314429  179898 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751542995.314433  179898 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751542995.314436  179898 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-03 13:43:15.317426: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[32m[I 2025-07-03 13:43:17,969]\u001b[0m A new study created in memory with name: no-name-3726f60d-80a8-4440-ba16-89e4c7783b0e\u001b[0m\n",
      "2025-07-03 13:43:19.826915: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "\u001b[32m[I 2025-07-03 13:44:37,700]\u001b[0m Trial 0 finished with value: 0.033984288573265076 and parameters: {'dropout': 0.32935865042871687, 'dense_units': 512, 'f_block1': 32, 'f_block2': 32, 'l2_reg': 2.843182362717023e-05, 'batch_size': 16}. Best is trial 0 with value: 0.033984288573265076.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 13:45:52,050]\u001b[0m Trial 1 finished with value: 0.03394445404410362 and parameters: {'dropout': 0.308096188561775, 'dense_units': 1024, 'f_block1': 32, 'f_block2': 16, 'l2_reg': 3.6319785785861567e-06, 'batch_size': 32}. Best is trial 1 with value: 0.03394445404410362.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 13:47:40,692]\u001b[0m Trial 2 finished with value: 0.04176841303706169 and parameters: {'dropout': 0.06586336127234348, 'dense_units': 256, 'f_block1': 32, 'f_block2': 32, 'l2_reg': 1.796765443995031e-06, 'batch_size': 32}. Best is trial 1 with value: 0.03394445404410362.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 13:49:17,999]\u001b[0m Trial 3 finished with value: 0.04132761433720589 and parameters: {'dropout': 0.20546907644200113, 'dense_units': 256, 'f_block1': 64, 'f_block2': 16, 'l2_reg': 3.571959388314097e-06, 'batch_size': 16}. Best is trial 1 with value: 0.03394445404410362.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 13:50:46,878]\u001b[0m Trial 4 finished with value: 0.033361032605171204 and parameters: {'dropout': 0.10493082428402248, 'dense_units': 4096, 'f_block1': 64, 'f_block2': 8, 'l2_reg': 4.022338104132606e-06, 'batch_size': 32}. Best is trial 4 with value: 0.033361032605171204.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 13:52:07,637]\u001b[0m Trial 5 finished with value: 0.040340859442949295 and parameters: {'dropout': 0.1430758807867658, 'dense_units': 512, 'f_block1': 32, 'f_block2': 32, 'l2_reg': 1.821842909828855e-05, 'batch_size': 16}. Best is trial 4 with value: 0.033361032605171204.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 13:52:48,172]\u001b[0m Trial 6 finished with value: 0.03063143417239189 and parameters: {'dropout': 0.1135409072261552, 'dense_units': 1024, 'f_block1': 64, 'f_block2': 32, 'l2_reg': 1.4632933269120382e-05, 'batch_size': 8}. Best is trial 6 with value: 0.03063143417239189.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 13:52:56,126]\u001b[0m Trial 7 finished with value: 0.474057137966156 and parameters: {'dropout': 0.17313570518816757, 'dense_units': 128, 'f_block1': 32, 'f_block2': 8, 'l2_reg': 2.5200835501750714e-05, 'batch_size': 32}. Best is trial 6 with value: 0.03063143417239189.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 13:54:09,168]\u001b[0m Trial 8 finished with value: 0.03399432450532913 and parameters: {'dropout': 0.3319159357252521, 'dense_units': 1024, 'f_block1': 64, 'f_block2': 32, 'l2_reg': 1.7867525500475424e-05, 'batch_size': 16}. Best is trial 6 with value: 0.03063143417239189.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 13:55:12,176]\u001b[0m Trial 9 finished with value: 0.026545051485300064 and parameters: {'dropout': 0.08581148342022647, 'dense_units': 2048, 'f_block1': 64, 'f_block2': 32, 'l2_reg': 2.732410445531028e-06, 'batch_size': 16}. Best is trial 9 with value: 0.026545051485300064.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 13:55:54,718]\u001b[0m Trial 10 finished with value: 0.0356205590069294 and parameters: {'dropout': 0.0019444803866635746, 'dense_units': 2048, 'f_block1': 64, 'f_block2': 16, 'l2_reg': 8.352030575549613e-05, 'batch_size': 8}. Best is trial 9 with value: 0.026545051485300064.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 13:56:47,008]\u001b[0m Trial 11 finished with value: 0.025065738707780838 and parameters: {'dropout': 0.04476495057742924, 'dense_units': 2048, 'f_block1': 64, 'f_block2': 32, 'l2_reg': 7.400534379427298e-06, 'batch_size': 8}. Best is trial 11 with value: 0.025065738707780838.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 13:57:29,471]\u001b[0m Trial 12 finished with value: 0.026329372078180313 and parameters: {'dropout': 0.0034053729496060503, 'dense_units': 2048, 'f_block1': 64, 'f_block2': 32, 'l2_reg': 1.231854385950981e-06, 'batch_size': 8}. Best is trial 11 with value: 0.025065738707780838.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 13:58:20,497]\u001b[0m Trial 13 finished with value: 0.026874085888266563 and parameters: {'dropout': 0.0033694866200254248, 'dense_units': 2048, 'f_block1': 64, 'f_block2': 32, 'l2_reg': 1.2207213332152404e-06, 'batch_size': 8}. Best is trial 11 with value: 0.025065738707780838.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 13:59:20,382]\u001b[0m Trial 14 finished with value: 0.02806018851697445 and parameters: {'dropout': 0.2505326401095793, 'dense_units': 2048, 'f_block1': 64, 'f_block2': 32, 'l2_reg': 6.617777126473782e-06, 'batch_size': 8}. Best is trial 11 with value: 0.025065738707780838.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 13:59:36,918]\u001b[0m Trial 15 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:00:06,244]\u001b[0m Trial 16 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:00:50,685]\u001b[0m Trial 17 finished with value: 0.03308362141251564 and parameters: {'dropout': 0.03872869297180547, 'dense_units': 4096, 'f_block1': 64, 'f_block2': 32, 'l2_reg': 6.741706638159599e-05, 'batch_size': 8}. Best is trial 11 with value: 0.025065738707780838.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:01:42,137]\u001b[0m Trial 18 finished with value: 0.026425713673233986 and parameters: {'dropout': 0.21664011641506487, 'dense_units': 2048, 'f_block1': 64, 'f_block2': 8, 'l2_reg': 4.1958488041978894e-05, 'batch_size': 8}. Best is trial 11 with value: 0.025065738707780838.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:02:32,008]\u001b[0m Trial 19 finished with value: 0.02828095480799675 and parameters: {'dropout': 0.028688191825098238, 'dense_units': 2048, 'f_block1': 64, 'f_block2': 16, 'l2_reg': 2.0556973645411086e-06, 'batch_size': 8}. Best is trial 11 with value: 0.025065738707780838.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:03:16,070]\u001b[0m Trial 20 finished with value: 0.02857729233801365 and parameters: {'dropout': 0.14648866392243454, 'dense_units': 2048, 'f_block1': 64, 'f_block2': 32, 'l2_reg': 5.724187805276204e-06, 'batch_size': 8}. Best is trial 11 with value: 0.025065738707780838.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:04:09,596]\u001b[0m Trial 21 finished with value: 0.03006911277770996 and parameters: {'dropout': 0.21692565254886262, 'dense_units': 2048, 'f_block1': 64, 'f_block2': 8, 'l2_reg': 4.538634282180064e-05, 'batch_size': 8}. Best is trial 11 with value: 0.025065738707780838.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:04:26,104]\u001b[0m Trial 22 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:04:42,632]\u001b[0m Trial 23 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:04:59,741]\u001b[0m Trial 24 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:05:15,910]\u001b[0m Trial 25 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:05:33,596]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:05:50,323]\u001b[0m Trial 27 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:06:27,262]\u001b[0m Trial 28 finished with value: 0.024167746305465698 and parameters: {'dropout': 0.18230736745592796, 'dense_units': 4096, 'f_block1': 64, 'f_block2': 16, 'l2_reg': 2.4869715458441857e-06, 'batch_size': 8}. Best is trial 28 with value: 0.024167746305465698.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:06:42,452]\u001b[0m Trial 29 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:07:00,317]\u001b[0m Trial 30 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:07:18,964]\u001b[0m Trial 31 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:07:36,238]\u001b[0m Trial 32 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:08:18,931]\u001b[0m Trial 33 finished with value: 0.02601456083357334 and parameters: {'dropout': 0.17180824223214802, 'dense_units': 4096, 'f_block1': 64, 'f_block2': 32, 'l2_reg': 1.4936651840637448e-06, 'batch_size': 8}. Best is trial 28 with value: 0.024167746305465698.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:08:36,547]\u001b[0m Trial 34 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:09:19,548]\u001b[0m Trial 35 finished with value: 0.024497682228684425 and parameters: {'dropout': 0.3285947600801849, 'dense_units': 4096, 'f_block1': 64, 'f_block2': 32, 'l2_reg': 1.0270999975298642e-06, 'batch_size': 8}. Best is trial 28 with value: 0.024167746305465698.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:09:45,157]\u001b[0m Trial 36 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:10:03,248]\u001b[0m Trial 37 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:10:20,988]\u001b[0m Trial 38 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:10:41,443]\u001b[0m Trial 39 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:10:58,303]\u001b[0m Trial 40 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:12:04,509]\u001b[0m Trial 41 finished with value: 0.02260935679078102 and parameters: {'dropout': 0.11500374505618277, 'dense_units': 4096, 'f_block1': 64, 'f_block2': 32, 'l2_reg': 1.4465885171866581e-06, 'batch_size': 8}. Best is trial 41 with value: 0.02260935679078102.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:12:59,022]\u001b[0m Trial 42 finished with value: 0.023772919550538063 and parameters: {'dropout': 0.12325357317042053, 'dense_units': 4096, 'f_block1': 64, 'f_block2': 32, 'l2_reg': 2.1502426619280684e-06, 'batch_size': 8}. Best is trial 41 with value: 0.02260935679078102.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:13:45,010]\u001b[0m Trial 43 finished with value: 0.023632941767573357 and parameters: {'dropout': 0.112422160413764, 'dense_units': 4096, 'f_block1': 64, 'f_block2': 32, 'l2_reg': 2.1083953543831523e-06, 'batch_size': 8}. Best is trial 41 with value: 0.02260935679078102.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:14:26,912]\u001b[0m Trial 44 finished with value: 0.025293543934822083 and parameters: {'dropout': 0.11272750248662498, 'dense_units': 4096, 'f_block1': 64, 'f_block2': 32, 'l2_reg': 2.1809360309384263e-06, 'batch_size': 8}. Best is trial 41 with value: 0.02260935679078102.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:14:47,532]\u001b[0m Trial 45 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:15:06,346]\u001b[0m Trial 46 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:15:49,680]\u001b[0m Trial 47 finished with value: 0.024380967020988464 and parameters: {'dropout': 0.12884502154821478, 'dense_units': 4096, 'f_block1': 64, 'f_block2': 32, 'l2_reg': 1.8126586697006448e-06, 'batch_size': 8}. Best is trial 41 with value: 0.02260935679078102.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:16:31,826]\u001b[0m Trial 48 finished with value: 0.025904471054673195 and parameters: {'dropout': 0.1260337186585609, 'dense_units': 4096, 'f_block1': 64, 'f_block2': 32, 'l2_reg': 1.850941848858806e-06, 'batch_size': 8}. Best is trial 41 with value: 0.02260935679078102.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:17:29,907]\u001b[0m Trial 49 finished with value: 0.027604352682828903 and parameters: {'dropout': 0.07063471034562127, 'dense_units': 1024, 'f_block1': 64, 'f_block2': 32, 'l2_reg': 2.384157201136462e-06, 'batch_size': 8}. Best is trial 41 with value: 0.02260935679078102.\u001b[0m\n",
      "\n",
      "Best hyperparameters:\n",
      "dropout: 0.11500374505618277\n",
      "dense_units: 4096\n",
      "f_block1: 64\n",
      "f_block2: 32\n",
      "l2_reg: 1.4465885171866581e-06\n",
      "batch_size: 8\n",
      "\n",
      "Saved best parameters to: /home/ameral/master/param2weld/experiments/optuna/results/midmode=median__mae80_ssim20/best_hyperparams_2025-07-03_14-17-29.json\n"
     ]
    }
   ],
   "source": [
    "!python -m param2weld.scripts.tune_optuna --fixed_params experiments/optuna/configs/fixed_median_mae80_ssim20.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99167093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-03 14:17:35.987871: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-03 14:17:35.991134: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-03 14:17:35.998897: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751545056.010667  535399 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751545056.014208  535399 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751545056.025618  535399 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751545056.025639  535399 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751545056.025642  535399 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751545056.025645  535399 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-03 14:17:36.028630: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[32m[I 2025-07-03 14:17:38,373]\u001b[0m A new study created in memory with name: no-name-3acd49d8-262e-4208-a223-3f67e4b62b9c\u001b[0m\n",
      "2025-07-03 14:17:39.838654: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "\u001b[32m[I 2025-07-03 14:20:09,211]\u001b[0m Trial 0 finished with value: 0.09765684604644775 and parameters: {'dropout': 0.38885113184044756, 'dense_units': 128, 'f_block1': 64, 'f_block2': 32, 'l2_reg': 2.1496415251041257e-06, 'batch_size': 32}. Best is trial 0 with value: 0.09765684604644775.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:20:45,141]\u001b[0m Trial 1 finished with value: 0.02283918485045433 and parameters: {'dropout': 0.08850733201249153, 'dense_units': 4096, 'f_block1': 32, 'f_block2': 16, 'l2_reg': 2.4949040648626173e-05, 'batch_size': 8}. Best is trial 1 with value: 0.02283918485045433.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:21:49,828]\u001b[0m Trial 2 finished with value: 0.02315666526556015 and parameters: {'dropout': 0.25728355491716887, 'dense_units': 4096, 'f_block1': 64, 'f_block2': 16, 'l2_reg': 1.1674779259001259e-05, 'batch_size': 16}. Best is trial 1 with value: 0.02283918485045433.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:23:04,538]\u001b[0m Trial 3 finished with value: 0.022100595757365227 and parameters: {'dropout': 0.0529383820280486, 'dense_units': 4096, 'f_block1': 32, 'f_block2': 16, 'l2_reg': 2.9715207833352416e-06, 'batch_size': 32}. Best is trial 3 with value: 0.022100595757365227.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:24:45,852]\u001b[0m Trial 4 finished with value: 0.035770874470472336 and parameters: {'dropout': 0.35680172952915074, 'dense_units': 512, 'f_block1': 64, 'f_block2': 32, 'l2_reg': 3.623245509984795e-06, 'batch_size': 32}. Best is trial 3 with value: 0.022100595757365227.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:24:53,210]\u001b[0m Trial 5 finished with value: 0.470320463180542 and parameters: {'dropout': 0.011072503655507672, 'dense_units': 512, 'f_block1': 32, 'f_block2': 8, 'l2_reg': 1.6612576537286776e-05, 'batch_size': 32}. Best is trial 3 with value: 0.022100595757365227.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:26:04,037]\u001b[0m Trial 6 finished with value: 0.030506795272231102 and parameters: {'dropout': 0.07796305117088523, 'dense_units': 512, 'f_block1': 64, 'f_block2': 8, 'l2_reg': 1.4509843708118941e-05, 'batch_size': 16}. Best is trial 3 with value: 0.022100595757365227.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:27:36,650]\u001b[0m Trial 7 finished with value: 0.024789959192276 and parameters: {'dropout': 0.019642084882605507, 'dense_units': 256, 'f_block1': 32, 'f_block2': 32, 'l2_reg': 1.357572862387475e-06, 'batch_size': 8}. Best is trial 3 with value: 0.022100595757365227.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:29:29,071]\u001b[0m Trial 8 finished with value: 0.06163535267114639 and parameters: {'dropout': 0.25796625192893535, 'dense_units': 128, 'f_block1': 64, 'f_block2': 32, 'l2_reg': 1.0404563881623507e-05, 'batch_size': 16}. Best is trial 3 with value: 0.022100595757365227.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:30:44,332]\u001b[0m Trial 9 finished with value: 0.028956880792975426 and parameters: {'dropout': 0.06532094998895435, 'dense_units': 1024, 'f_block1': 64, 'f_block2': 32, 'l2_reg': 5.1846703037978024e-05, 'batch_size': 16}. Best is trial 3 with value: 0.022100595757365227.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:30:58,530]\u001b[0m Trial 10 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:31:39,224]\u001b[0m Trial 11 finished with value: 0.026566511020064354 and parameters: {'dropout': 0.13461690586543623, 'dense_units': 4096, 'f_block1': 32, 'f_block2': 16, 'l2_reg': 5.0517675543598916e-05, 'batch_size': 8}. Best is trial 3 with value: 0.022100595757365227.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:32:17,172]\u001b[0m Trial 12 finished with value: 0.023439180105924606 and parameters: {'dropout': 0.10407501763640946, 'dense_units': 4096, 'f_block1': 32, 'f_block2': 16, 'l2_reg': 2.736076544946083e-05, 'batch_size': 8}. Best is trial 3 with value: 0.022100595757365227.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:33:14,364]\u001b[0m Trial 13 finished with value: 0.022344492375850677 and parameters: {'dropout': 0.1940814163969758, 'dense_units': 4096, 'f_block1': 32, 'f_block2': 16, 'l2_reg': 5.211622395770834e-06, 'batch_size': 8}. Best is trial 3 with value: 0.022100595757365227.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:33:28,444]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:33:42,326]\u001b[0m Trial 15 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:34:22,100]\u001b[0m Trial 16 finished with value: 0.025803619995713234 and parameters: {'dropout': 0.1650364693430478, 'dense_units': 2048, 'f_block1': 32, 'f_block2': 16, 'l2_reg': 2.1319933451479356e-06, 'batch_size': 8}. Best is trial 3 with value: 0.022100595757365227.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:34:34,321]\u001b[0m Trial 17 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:34:48,583]\u001b[0m Trial 18 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:35:33,599]\u001b[0m Trial 19 finished with value: 0.029535647481679916 and parameters: {'dropout': 0.30792998977022423, 'dense_units': 4096, 'f_block1': 32, 'f_block2': 16, 'l2_reg': 5.55856454055356e-06, 'batch_size': 8}. Best is trial 3 with value: 0.022100595757365227.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:35:46,620]\u001b[0m Trial 20 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:36:31,430]\u001b[0m Trial 21 finished with value: 0.027580108493566513 and parameters: {'dropout': 0.08910001473489491, 'dense_units': 4096, 'f_block1': 32, 'f_block2': 16, 'l2_reg': 8.995739305522557e-05, 'batch_size': 8}. Best is trial 3 with value: 0.022100595757365227.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:37:11,313]\u001b[0m Trial 22 finished with value: 0.02384154498577118 and parameters: {'dropout': 0.16114270668982703, 'dense_units': 4096, 'f_block1': 32, 'f_block2': 16, 'l2_reg': 2.5052558085394107e-05, 'batch_size': 8}. Best is trial 3 with value: 0.022100595757365227.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:37:51,484]\u001b[0m Trial 23 finished with value: 0.022404570132493973 and parameters: {'dropout': 0.039399051021267784, 'dense_units': 4096, 'f_block1': 32, 'f_block2': 16, 'l2_reg': 2.1431015487104104e-05, 'batch_size': 8}. Best is trial 3 with value: 0.022100595757365227.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:38:22,972]\u001b[0m Trial 24 finished with value: 0.022549385204911232 and parameters: {'dropout': 0.04669123850098717, 'dense_units': 4096, 'f_block1': 32, 'f_block2': 16, 'l2_reg': 3.4179880537509713e-06, 'batch_size': 8}. Best is trial 3 with value: 0.022100595757365227.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:38:37,094]\u001b[0m Trial 25 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:38:51,091]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:39:21,477]\u001b[0m Trial 27 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:39:34,599]\u001b[0m Trial 28 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:39:49,757]\u001b[0m Trial 29 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:40:06,440]\u001b[0m Trial 30 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:40:39,204]\u001b[0m Trial 31 finished with value: 0.022381968796253204 and parameters: {'dropout': 0.042392752283688516, 'dense_units': 4096, 'f_block1': 32, 'f_block2': 16, 'l2_reg': 1.7241751162797524e-06, 'batch_size': 8}. Best is trial 3 with value: 0.022100595757365227.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:41:08,672]\u001b[0m Trial 32 finished with value: 0.024481618776917458 and parameters: {'dropout': 0.0015196750391087699, 'dense_units': 4096, 'f_block1': 32, 'f_block2': 16, 'l2_reg': 2.062645859822089e-06, 'batch_size': 8}. Best is trial 3 with value: 0.022100595757365227.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:41:39,532]\u001b[0m Trial 33 finished with value: 0.023041803389787674 and parameters: {'dropout': 0.10131400388360978, 'dense_units': 4096, 'f_block1': 32, 'f_block2': 16, 'l2_reg': 1.7443010734730926e-06, 'batch_size': 8}. Best is trial 3 with value: 0.022100595757365227.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:42:18,411]\u001b[0m Trial 34 finished with value: 0.02003823034465313 and parameters: {'dropout': 0.026154080787416753, 'dense_units': 4096, 'f_block1': 32, 'f_block2': 16, 'l2_reg': 1.0474999578192336e-06, 'batch_size': 8}. Best is trial 34 with value: 0.02003823034465313.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:43:02,524]\u001b[0m Trial 35 finished with value: 0.020371541380882263 and parameters: {'dropout': 0.07431727594602244, 'dense_units': 4096, 'f_block1': 64, 'f_block2': 16, 'l2_reg': 1.0472581803333187e-06, 'batch_size': 8}. Best is trial 34 with value: 0.02003823034465313.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:43:18,929]\u001b[0m Trial 36 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:43:35,547]\u001b[0m Trial 37 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:43:53,393]\u001b[0m Trial 38 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:44:12,148]\u001b[0m Trial 39 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:44:27,503]\u001b[0m Trial 40 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:45:02,188]\u001b[0m Trial 41 finished with value: 0.023692741990089417 and parameters: {'dropout': 0.08523676427226116, 'dense_units': 4096, 'f_block1': 64, 'f_block2': 16, 'l2_reg': 1.8628342331131962e-06, 'batch_size': 8}. Best is trial 34 with value: 0.02003823034465313.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:45:10,458]\u001b[0m Trial 42 finished with value: 0.4926992356777191 and parameters: {'dropout': 0.05426273661136467, 'dense_units': 4096, 'f_block1': 32, 'f_block2': 16, 'l2_reg': 1.6065943485391842e-06, 'batch_size': 8}. Best is trial 34 with value: 0.02003823034465313.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:45:47,621]\u001b[0m Trial 43 finished with value: 0.025034796446561813 and parameters: {'dropout': 0.021876167809573074, 'dense_units': 4096, 'f_block1': 64, 'f_block2': 16, 'l2_reg': 2.6133228358495838e-06, 'batch_size': 8}. Best is trial 34 with value: 0.02003823034465313.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:46:23,991]\u001b[0m Trial 44 finished with value: 0.021565506234765053 and parameters: {'dropout': 0.10358440764816225, 'dense_units': 4096, 'f_block1': 32, 'f_block2': 32, 'l2_reg': 3.885872350192612e-06, 'batch_size': 8}. Best is trial 34 with value: 0.02003823034465313.\u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:46:39,871]\u001b[0m Trial 45 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:46:59,596]\u001b[0m Trial 46 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:47:30,097]\u001b[0m Trial 47 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:47:47,019]\u001b[0m Trial 48 pruned. \u001b[0m\n",
      "\u001b[32m[I 2025-07-03 14:47:55,681]\u001b[0m Trial 49 finished with value: 0.4667133390903473 and parameters: {'dropout': 0.14166055528811727, 'dense_units': 512, 'f_block1': 32, 'f_block2': 32, 'l2_reg': 9.47091000663376e-06, 'batch_size': 32}. Best is trial 34 with value: 0.02003823034465313.\u001b[0m\n",
      "\n",
      "Best hyperparameters:\n",
      "dropout: 0.026154080787416753\n",
      "dense_units: 4096\n",
      "f_block1: 32\n",
      "f_block2: 16\n",
      "l2_reg: 1.0474999578192336e-06\n",
      "batch_size: 8\n",
      "\n",
      "Saved best parameters to: /home/ameral/master/param2weld/experiments/optuna/results/midmode=mean__mae80_ssim20/best_hyperparams_2025-07-03_14-47-55.json\n"
     ]
    }
   ],
   "source": [
    "!python -m param2weld.scripts.tune_optuna --fixed_params experiments/optuna/configs/fixed_mean_mae80_ssim20.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f88cbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-03 16:17:48.345603: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-03 16:17:48.349257: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-03 16:17:48.357341: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751552268.369605  913499 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751552268.373423  913499 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751552268.385445  913499 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751552268.385468  913499 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751552268.385472  913499 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751552268.385475  913499 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-03 16:17:48.388586: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[16:17:50] WARNING - Ignoring missing params_json file: experiments/optuna/results/midmode=median__mae80_ssim20/best_hyperparams_2025-07-03_14-01-00.json\n",
      "\n",
      "Starting fold 1/10\n",
      "2025-07-03 16:17:52.051338: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "Epoch 1/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.5147 - mae: 0.4059 - rmse: 0.4487 - val_loss: 0.4586 - val_mae: 0.4600 - val_rmse: 0.4679 - learning_rate: 3.0000e-04\n",
      "Epoch 2/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.4462 - mae: 0.3313 - rmse: 0.3780 - val_loss: 0.4458 - val_mae: 0.4460 - val_rmse: 0.4535 - learning_rate: 3.0000e-04\n",
      "Epoch 3/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.3842 - mae: 0.2699 - rmse: 0.3243 - val_loss: 0.4276 - val_mae: 0.4259 - val_rmse: 0.4334 - learning_rate: 3.0000e-04\n",
      "Epoch 4/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.3285 - mae: 0.2214 - rmse: 0.2878 - val_loss: 0.4021 - val_mae: 0.3967 - val_rmse: 0.4051 - learning_rate: 3.0000e-04\n",
      "Epoch 5/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2736 - mae: 0.1834 - rmse: 0.2592 - val_loss: 0.3703 - val_mae: 0.3593 - val_rmse: 0.3707 - learning_rate: 3.0000e-04\n",
      "Epoch 6/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.2347 - mae: 0.1556 - rmse: 0.2413 - val_loss: 0.3380 - val_mae: 0.3211 - val_rmse: 0.3385 - learning_rate: 3.0000e-04\n",
      "Epoch 7/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1968 - mae: 0.1372 - rmse: 0.2294 - val_loss: 0.3093 - val_mae: 0.2864 - val_rmse: 0.3126 - learning_rate: 3.0000e-04\n",
      "Epoch 8/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1643 - mae: 0.1170 - rmse: 0.2144 - val_loss: 0.2830 - val_mae: 0.2559 - val_rmse: 0.2929 - learning_rate: 3.0000e-04\n",
      "Epoch 9/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1530 - mae: 0.1141 - rmse: 0.2200 - val_loss: 0.2610 - val_mae: 0.2296 - val_rmse: 0.2793 - learning_rate: 3.0000e-04\n",
      "Epoch 10/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1255 - mae: 0.0951 - rmse: 0.1921 - val_loss: 0.2378 - val_mae: 0.2056 - val_rmse: 0.2695 - learning_rate: 3.0000e-04\n",
      "Epoch 11/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1122 - mae: 0.0886 - rmse: 0.1855 - val_loss: 0.2179 - val_mae: 0.1853 - val_rmse: 0.2641 - learning_rate: 3.0000e-04\n",
      "Epoch 12/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.1000 - mae: 0.0789 - rmse: 0.1719 - val_loss: 0.2040 - val_mae: 0.1703 - val_rmse: 0.2608 - learning_rate: 3.0000e-04\n",
      "Epoch 13/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1047 - mae: 0.0790 - rmse: 0.1737 - val_loss: 0.1935 - val_mae: 0.1589 - val_rmse: 0.2599 - learning_rate: 3.0000e-04\n",
      "Epoch 14/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0833 - mae: 0.0640 - rmse: 0.1444 - val_loss: 0.1849 - val_mae: 0.1504 - val_rmse: 0.2593 - learning_rate: 3.0000e-04\n",
      "Epoch 15/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0730 - mae: 0.0576 - rmse: 0.1335 - val_loss: 0.1783 - val_mae: 0.1438 - val_rmse: 0.2591 - learning_rate: 3.0000e-04\n",
      "Epoch 16/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0724 - mae: 0.0561 - rmse: 0.1345 - val_loss: 0.1730 - val_mae: 0.1380 - val_rmse: 0.2575 - learning_rate: 3.0000e-04\n",
      "Epoch 17/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0657 - mae: 0.0511 - rmse: 0.1253 - val_loss: 0.1687 - val_mae: 0.1334 - val_rmse: 0.2554 - learning_rate: 3.0000e-04\n",
      "Epoch 18/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0633 - mae: 0.0476 - rmse: 0.1192 - val_loss: 0.1648 - val_mae: 0.1293 - val_rmse: 0.2548 - learning_rate: 3.0000e-04\n",
      "Epoch 19/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0579 - mae: 0.0443 - rmse: 0.1108 - val_loss: 0.1603 - val_mae: 0.1247 - val_rmse: 0.2510 - learning_rate: 3.0000e-04\n",
      "Epoch 20/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0561 - mae: 0.0427 - rmse: 0.1103 - val_loss: 0.1570 - val_mae: 0.1215 - val_rmse: 0.2505 - learning_rate: 3.0000e-04\n",
      "Epoch 21/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0484 - mae: 0.0382 - rmse: 0.0988 - val_loss: 0.1538 - val_mae: 0.1180 - val_rmse: 0.2465 - learning_rate: 3.0000e-04\n",
      "Epoch 22/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0494 - mae: 0.0383 - rmse: 0.1033 - val_loss: 0.1501 - val_mae: 0.1145 - val_rmse: 0.2432 - learning_rate: 3.0000e-04\n",
      "Epoch 23/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0424 - mae: 0.0337 - rmse: 0.0909 - val_loss: 0.1474 - val_mae: 0.1118 - val_rmse: 0.2407 - learning_rate: 3.0000e-04\n",
      "Epoch 24/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0424 - mae: 0.0332 - rmse: 0.0909 - val_loss: 0.1426 - val_mae: 0.1074 - val_rmse: 0.2357 - learning_rate: 3.0000e-04\n",
      "Epoch 25/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0445 - mae: 0.0341 - rmse: 0.0947 - val_loss: 0.1384 - val_mae: 0.1037 - val_rmse: 0.2314 - learning_rate: 3.0000e-04\n",
      "Epoch 26/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0369 - mae: 0.0292 - rmse: 0.0778 - val_loss: 0.1362 - val_mae: 0.1015 - val_rmse: 0.2291 - learning_rate: 3.0000e-04\n",
      "Epoch 27/500\n",
      "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 0.0363 - mae: 0.0286 - rmse: 0.0792Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/ameral/master/param2weld/param2weld/cli/main.py\", line 67, in <module>\n",
      "    main()\n",
      "  File \"/home/ameral/master/param2weld/param2weld/cli/main.py\", line 58, in main\n",
      "    run_cv_training(\n",
      "  File \"/home/ameral/master/param2weld/param2weld/train/trainer.py\", line 115, in run_cv_training\n",
      "    history = model.fit(\n",
      "              ^^^^^^^^^^\n",
      "  File \"/home/ameral/master/param2weld/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ameral/master/param2weld/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 401, in fit\n",
      "    val_logs = self.evaluate(\n",
      "               ^^^^^^^^^^^^^^\n",
      "  File \"/home/ameral/master/param2weld/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ameral/master/param2weld/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 487, in evaluate\n",
      "    for step, iterator in epoch_iterator:\n",
      "  File \"/home/ameral/master/param2weld/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 740, in __next__\n",
      "    return next(self._epoch_iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ameral/master/param2weld/.venv/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py\", line 121, in _enumerate_iterator\n",
      "    self._current_iterator = iter(self._get_iterator())\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ameral/master/param2weld/.venv/lib/python3.12/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 501, in __iter__\n",
      "    return iterator_ops.OwnedIterator(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ameral/master/param2weld/.venv/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 709, in __init__\n",
      "    self._create_iterator(dataset)\n",
      "  File \"/home/ameral/master/param2weld/.venv/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 731, in _create_iterator\n",
      "    gen_dataset_ops.anonymous_iterator_v3(\n",
      "  File \"/home/ameral/master/param2weld/.venv/lib/python3.12/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 204, in anonymous_iterator_v3\n",
      "    _result = pywrap_tfe.TFE_Py_FastPathExecute(\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python3 -m param2weld.cli.main train \\\n",
    "  --data_dir ./data \\\n",
    "  --params_json experiments/optuna/results/midmode=median__mae80_ssim20/best_hyperparams_2025-07-03_14-17-29.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
